{
  "components": {
    "schemas": {
      "ClassifierModel": {
        "properties": {
          "id2label": {
            "additionalProperties": {
              "type": "string"
            },
            "example": {
              "0": "LABEL"
            },
            "type": "object"
          },
          "label2id": {
            "additionalProperties": {
              "minimum": 0,
              "type": "integer"
            },
            "example": {
              "LABEL": 0
            },
            "type": "object"
          }
        },
        "required": [
          "id2label",
          "label2id"
        ],
        "type": "object"
      },
      "DecodeRequest": {
        "properties": {
          "ids": {
            "$ref": "#/components/schemas/InputIds"
          },
          "skip_special_tokens": {
            "default": "true",
            "example": "true",
            "type": "boolean"
          }
        },
        "required": [
          "ids"
        ],
        "type": "object"
      },
      "DecodeResponse": {
        "example": [
          "test"
        ],
        "items": {
          "type": "string"
        },
        "type": "array"
      },
      "EmbedAllRequest": {
        "properties": {
          "inputs": {
            "$ref": "#/components/schemas/Input"
          },
          "prompt_name": {
            "default": "null",
            "description": "The name of the prompt that should be used by for encoding. If not set, no prompt\nwill be applied.\n\nMust be a key in the `sentence-transformers` configuration `prompts` dictionary.\n\nFor example if ``prompt_name`` is \"query\" and the ``prompts`` is {\"query\": \"query: \", ...},\nthen the sentence \"What is the capital of France?\" will be encoded as\n\"query: What is the capital of France?\" because the prompt text will be prepended before\nany text to encode.",
            "example": "null",
            "nullable": true,
            "type": "string"
          },
          "truncate": {
            "default": "false",
            "example": "false",
            "nullable": true,
            "type": "boolean"
          },
          "truncation_direction": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TruncationDirection"
              }
            ],
            "default": "right"
          }
        },
        "required": [
          "inputs"
        ],
        "type": "object"
      },
      "EmbedAllResponse": {
        "example": [
          [
            [
              0.0,
              1.0,
              2.0
            ]
          ]
        ],
        "items": {
          "items": {
            "items": {
              "format": "float",
              "type": "number"
            },
            "type": "array"
          },
          "type": "array"
        },
        "type": "array"
      },
      "EmbedRequest": {
        "properties": {
          "inputs": {
            "$ref": "#/components/schemas/Input"
          },
          "normalize": {
            "default": "true",
            "example": "true",
            "type": "boolean"
          },
          "prompt_name": {
            "default": "null",
            "description": "The name of the prompt that should be used by for encoding. If not set, no prompt\nwill be applied.\n\nMust be a key in the `sentence-transformers` configuration `prompts` dictionary.\n\nFor example if ``prompt_name`` is \"query\" and the ``prompts`` is {\"query\": \"query: \", ...},\nthen the sentence \"What is the capital of France?\" will be encoded as\n\"query: What is the capital of France?\" because the prompt text will be prepended before\nany text to encode.",
            "example": "null",
            "nullable": true,
            "type": "string"
          },
          "truncate": {
            "default": "false",
            "example": "false",
            "nullable": true,
            "type": "boolean"
          },
          "truncation_direction": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TruncationDirection"
              }
            ],
            "default": "right"
          }
        },
        "required": [
          "inputs"
        ],
        "type": "object"
      },
      "EmbedResponse": {
        "example": [
          [
            0.0,
            1.0,
            2.0
          ]
        ],
        "items": {
          "items": {
            "format": "float",
            "type": "number"
          },
          "type": "array"
        },
        "type": "array"
      },
      "EmbedSparseRequest": {
        "properties": {
          "inputs": {
            "$ref": "#/components/schemas/Input"
          },
          "prompt_name": {
            "default": "null",
            "description": "The name of the prompt that should be used by for encoding. If not set, no prompt\nwill be applied.\n\nMust be a key in the `sentence-transformers` configuration `prompts` dictionary.\n\nFor example if ``prompt_name`` is \"query\" and the ``prompts`` is {\"query\": \"query: \", ...},\nthen the sentence \"What is the capital of France?\" will be encoded as\n\"query: What is the capital of France?\" because the prompt text will be prepended before\nany text to encode.",
            "example": "null",
            "nullable": true,
            "type": "string"
          },
          "truncate": {
            "default": "false",
            "example": "false",
            "nullable": true,
            "type": "boolean"
          },
          "truncation_direction": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TruncationDirection"
              }
            ],
            "default": "right"
          }
        },
        "required": [
          "inputs"
        ],
        "type": "object"
      },
      "EmbedSparseResponse": {
        "items": {
          "items": {
            "$ref": "#/components/schemas/SparseValue"
          },
          "type": "array"
        },
        "type": "array"
      },
      "Embedding": {
        "oneOf": [
          {
            "items": {
              "format": "float",
              "type": "number"
            },
            "type": "array"
          },
          {
            "type": "string"
          }
        ]
      },
      "EmbeddingModel": {
        "properties": {
          "pooling": {
            "example": "cls",
            "type": "string"
          }
        },
        "required": [
          "pooling"
        ],
        "type": "object"
      },
      "EncodingFormat": {
        "enum": [
          "float",
          "base64"
        ],
        "type": "string"
      },
      "ErrorResponse": {
        "properties": {
          "error": {
            "type": "string"
          },
          "error_type": {
            "$ref": "#/components/schemas/ErrorType"
          }
        },
        "required": [
          "error",
          "error_type"
        ],
        "type": "object"
      },
      "ErrorType": {
        "enum": [
          "Unhealthy",
          "Backend",
          "Overloaded",
          "Validation",
          "Tokenizer"
        ],
        "type": "string"
      },
      "Info": {
        "properties": {
          "auto_truncate": {
            "type": "boolean"
          },
          "docker_label": {
            "example": "null",
            "nullable": true,
            "type": "string"
          },
          "max_batch_requests": {
            "default": "null",
            "example": "null",
            "minimum": 0,
            "nullable": true,
            "type": "integer"
          },
          "max_batch_tokens": {
            "example": "2048",
            "minimum": 0,
            "type": "integer"
          },
          "max_client_batch_size": {
            "example": "32",
            "minimum": 0,
            "type": "integer"
          },
          "max_concurrent_requests": {
            "description": "Router Parameters",
            "example": "128",
            "minimum": 0,
            "type": "integer"
          },
          "max_input_length": {
            "example": "512",
            "minimum": 0,
            "type": "integer"
          },
          "model_dtype": {
            "example": "float16",
            "type": "string"
          },
          "model_id": {
            "description": "Model info",
            "example": "thenlper/gte-base",
            "type": "string"
          },
          "model_sha": {
            "example": "fca14538aa9956a46526bd1d0d11d69e19b5a101",
            "nullable": true,
            "type": "string"
          },
          "model_type": {
            "$ref": "#/components/schemas/ModelType"
          },
          "sha": {
            "example": "null",
            "nullable": true,
            "type": "string"
          },
          "tokenization_workers": {
            "example": "4",
            "minimum": 0,
            "type": "integer"
          },
          "version": {
            "description": "Router Info",
            "example": "0.5.0",
            "type": "string"
          }
        },
        "required": [
          "model_id",
          "model_dtype",
          "model_type",
          "max_concurrent_requests",
          "max_input_length",
          "max_batch_tokens",
          "max_client_batch_size",
          "auto_truncate",
          "tokenization_workers",
          "version"
        ],
        "type": "object"
      },
      "Input": {
        "oneOf": [
          {
            "$ref": "#/components/schemas/InputType"
          },
          {
            "items": {
              "$ref": "#/components/schemas/InputType"
            },
            "type": "array"
          }
        ]
      },
      "InputIds": {
        "oneOf": [
          {
            "items": {
              "format": "int32",
              "minimum": 0,
              "type": "integer"
            },
            "type": "array"
          },
          {
            "items": {
              "items": {
                "format": "int32",
                "minimum": 0,
                "type": "integer"
              },
              "type": "array"
            },
            "type": "array"
          }
        ]
      },
      "InputType": {
        "oneOf": [
          {
            "type": "string"
          },
          {
            "items": {
              "format": "int32",
              "minimum": 0,
              "type": "integer"
            },
            "type": "array"
          }
        ]
      },
      "ModelType": {
        "oneOf": [
          {
            "properties": {
              "classifier": {
                "$ref": "#/components/schemas/ClassifierModel"
              }
            },
            "required": [
              "classifier"
            ],
            "type": "object"
          },
          {
            "properties": {
              "embedding": {
                "$ref": "#/components/schemas/EmbeddingModel"
              }
            },
            "required": [
              "embedding"
            ],
            "type": "object"
          },
          {
            "properties": {
              "reranker": {
                "$ref": "#/components/schemas/ClassifierModel"
              }
            },
            "required": [
              "reranker"
            ],
            "type": "object"
          }
        ]
      },
      "OpenAICompatEmbedding": {
        "properties": {
          "embedding": {
            "$ref": "#/components/schemas/Embedding"
          },
          "index": {
            "example": "0",
            "minimum": 0,
            "type": "integer"
          },
          "object": {
            "example": "embedding",
            "type": "string"
          }
        },
        "required": [
          "object",
          "embedding",
          "index"
        ],
        "type": "object"
      },
      "OpenAICompatErrorResponse": {
        "properties": {
          "code": {
            "format": "int32",
            "minimum": 0,
            "type": "integer"
          },
          "error_type": {
            "$ref": "#/components/schemas/ErrorType"
          },
          "message": {
            "type": "string"
          }
        },
        "required": [
          "message",
          "code",
          "error_type"
        ],
        "type": "object"
      },
      "OpenAICompatRequest": {
        "properties": {
          "encoding_format": {
            "allOf": [
              {
                "$ref": "#/components/schemas/EncodingFormat"
              }
            ],
            "default": "float"
          },
          "input": {
            "$ref": "#/components/schemas/Input"
          },
          "model": {
            "example": "null",
            "nullable": true,
            "type": "string"
          },
          "user": {
            "example": "null",
            "nullable": true,
            "type": "string"
          }
        },
        "required": [
          "input"
        ],
        "type": "object"
      },
      "OpenAICompatResponse": {
        "properties": {
          "data": {
            "items": {
              "$ref": "#/components/schemas/OpenAICompatEmbedding"
            },
            "type": "array"
          },
          "model": {
            "example": "thenlper/gte-base",
            "type": "string"
          },
          "object": {
            "example": "list",
            "type": "string"
          },
          "usage": {
            "$ref": "#/components/schemas/OpenAICompatUsage"
          }
        },
        "required": [
          "object",
          "data",
          "model",
          "usage"
        ],
        "type": "object"
      },
      "OpenAICompatUsage": {
        "properties": {
          "prompt_tokens": {
            "example": "512",
            "minimum": 0,
            "type": "integer"
          },
          "total_tokens": {
            "example": "512",
            "minimum": 0,
            "type": "integer"
          }
        },
        "required": [
          "prompt_tokens",
          "total_tokens"
        ],
        "type": "object"
      },
      "PredictInput": {
        "description": "Model input. Can be either a single string, a pair of strings or a batch of mixed single and pairs of strings.",
        "example": "What is Deep Learning?",
        "oneOf": [
          {
            "description": "A single string",
            "type": "string"
          },
          {
            "description": "A pair of strings",
            "items": {
              "type": "string"
            },
            "maxItems": 2,
            "minItems": 2,
            "type": "array"
          },
          {
            "description": "A batch",
            "items": {
              "oneOf": [
                {
                  "description": "A single string",
                  "items": {
                    "type": "string"
                  },
                  "maxItems": 1,
                  "minItems": 1,
                  "type": "array"
                },
                {
                  "description": "A pair of strings",
                  "items": {
                    "type": "string"
                  },
                  "maxItems": 2,
                  "minItems": 2,
                  "type": "array"
                }
              ]
            },
            "type": "array"
          }
        ]
      },
      "PredictRequest": {
        "properties": {
          "inputs": {
            "$ref": "#/components/schemas/PredictInput"
          },
          "raw_scores": {
            "default": "false",
            "example": "false",
            "type": "boolean"
          },
          "truncate": {
            "default": "false",
            "example": "false",
            "nullable": true,
            "type": "boolean"
          },
          "truncation_direction": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TruncationDirection"
              }
            ],
            "default": "right"
          }
        },
        "required": [
          "inputs"
        ],
        "type": "object"
      },
      "PredictResponse": {
        "oneOf": [
          {
            "items": {
              "$ref": "#/components/schemas/Prediction"
            },
            "type": "array"
          },
          {
            "items": {
              "items": {
                "$ref": "#/components/schemas/Prediction"
              },
              "type": "array"
            },
            "type": "array"
          }
        ]
      },
      "Prediction": {
        "properties": {
          "label": {
            "example": "admiration",
            "type": "string"
          },
          "score": {
            "example": "0.5",
            "format": "float",
            "type": "number"
          }
        },
        "required": [
          "score",
          "label"
        ],
        "type": "object"
      },
      "Rank": {
        "properties": {
          "index": {
            "example": "0",
            "minimum": 0,
            "type": "integer"
          },
          "score": {
            "example": "1.0",
            "format": "float",
            "type": "number"
          },
          "text": {
            "default": "null",
            "example": "Deep Learning is ...",
            "nullable": true,
            "type": "string"
          }
        },
        "required": [
          "index",
          "score"
        ],
        "type": "object"
      },
      "RerankRequest": {
        "properties": {
          "query": {
            "example": "What is Deep Learning?",
            "type": "string"
          },
          "raw_scores": {
            "default": "false",
            "example": "false",
            "type": "boolean"
          },
          "return_text": {
            "default": "false",
            "example": "false",
            "type": "boolean"
          },
          "texts": {
            "example": [
              "Deep Learning is ..."
            ],
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "truncate": {
            "default": "false",
            "example": "false",
            "nullable": true,
            "type": "boolean"
          },
          "truncation_direction": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TruncationDirection"
              }
            ],
            "default": "right"
          }
        },
        "required": [
          "query",
          "texts"
        ],
        "type": "object"
      },
      "RerankResponse": {
        "items": {
          "$ref": "#/components/schemas/Rank"
        },
        "type": "array"
      },
      "SimilarityInput": {
        "properties": {
          "sentences": {
            "description": "A list of strings which will be compared against the source_sentence.",
            "example": [
              "What is Machine Learning?"
            ],
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "source_sentence": {
            "description": "The string that you wish to compare the other strings with. This can be a phrase, sentence,\nor longer passage, depending on the model being used.",
            "example": "What is Deep Learning?",
            "type": "string"
          }
        },
        "required": [
          "source_sentence",
          "sentences"
        ],
        "type": "object"
      },
      "SimilarityParameters": {
        "properties": {
          "prompt_name": {
            "default": "null",
            "description": "The name of the prompt that should be used by for encoding. If not set, no prompt\nwill be applied.\n\nMust be a key in the `sentence-transformers` configuration `prompts` dictionary.\n\nFor example if ``prompt_name`` is \"query\" and the ``prompts`` is {\"query\": \"query: \", ...},\nthen the sentence \"What is the capital of France?\" will be encoded as\n\"query: What is the capital of France?\" because the prompt text will be prepended before\nany text to encode.",
            "example": "null",
            "nullable": true,
            "type": "string"
          },
          "truncate": {
            "default": "false",
            "example": "false",
            "nullable": true,
            "type": "boolean"
          },
          "truncation_direction": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TruncationDirection"
              }
            ],
            "default": "right"
          }
        },
        "required": [
          "truncation_direction"
        ],
        "type": "object"
      },
      "SimilarityRequest": {
        "properties": {
          "inputs": {
            "$ref": "#/components/schemas/SimilarityInput"
          },
          "parameters": {
            "allOf": [
              {
                "$ref": "#/components/schemas/SimilarityParameters"
              }
            ],
            "default": "null",
            "nullable": true
          }
        },
        "required": [
          "inputs"
        ],
        "type": "object"
      },
      "SimilarityResponse": {
        "example": [
          0.0,
          1.0,
          0.5
        ],
        "items": {
          "format": "float",
          "type": "number"
        },
        "type": "array"
      },
      "SimpleToken": {
        "properties": {
          "id": {
            "example": 0,
            "format": "int32",
            "minimum": 0,
            "type": "integer"
          },
          "special": {
            "example": "false",
            "type": "boolean"
          },
          "start": {
            "example": 0,
            "minimum": 0,
            "nullable": true,
            "type": "integer"
          },
          "stop": {
            "example": 2,
            "minimum": 0,
            "nullable": true,
            "type": "integer"
          },
          "text": {
            "example": "test",
            "type": "string"
          }
        },
        "required": [
          "id",
          "text",
          "special"
        ],
        "type": "object"
      },
      "SparseValue": {
        "properties": {
          "index": {
            "minimum": 0,
            "type": "integer"
          },
          "value": {
            "format": "float",
            "type": "number"
          }
        },
        "required": [
          "index",
          "value"
        ],
        "type": "object"
      },
      "TokenizeInput": {
        "oneOf": [
          {
            "type": "string"
          },
          {
            "items": {
              "type": "string"
            },
            "type": "array"
          }
        ]
      },
      "TokenizeRequest": {
        "properties": {
          "add_special_tokens": {
            "default": "true",
            "example": "true",
            "type": "boolean"
          },
          "inputs": {
            "$ref": "#/components/schemas/TokenizeInput"
          },
          "prompt_name": {
            "default": "null",
            "description": "The name of the prompt that should be used by for encoding. If not set, no prompt\nwill be applied.\n\nMust be a key in the `sentence-transformers` configuration `prompts` dictionary.\n\nFor example if ``prompt_name`` is \"query\" and the ``prompts`` is {\"query\": \"query: \", ...},\nthen the sentence \"What is the capital of France?\" will be encoded as\n\"query: What is the capital of France?\" because the prompt text will be prepended before\nany text to encode.",
            "example": "null",
            "nullable": true,
            "type": "string"
          }
        },
        "required": [
          "inputs"
        ],
        "type": "object"
      },
      "TokenizeResponse": {
        "example": [
          [
            {
              "id": 0,
              "special": false,
              "start": 0,
              "stop": 2,
              "text": "test"
            }
          ]
        ],
        "items": {
          "items": {
            "$ref": "#/components/schemas/SimpleToken"
          },
          "type": "array"
        },
        "type": "array"
      },
      "TruncationDirection": {
        "enum": [
          "Left",
          "Right"
        ],
        "type": "string"
      }
    }
  },
  "info": {
    "contact": {
      "name": "Olivier Dehaene"
    },
    "description": "Text Embedding Webserver",
    "license": {
      "name": "Apache 2.0",
      "url": "https://www.apache.org/licenses/LICENSE-2.0"
    },
    "title": "Text Embeddings Inference",
    "version": "1.6.0"
  },
  "openapi": "3.0.3",
  "paths": {
    "/decode": {
      "post": {
        "operationId": "decode",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/DecodeRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/DecodeResponse"
                }
              }
            },
            "description": "Decoded ids"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "message": "Tokenization error",
                  "type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          }
        },
        "summary": "Decode input ids",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/embed": {
      "post": {
        "operationId": "embed",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/EmbedRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/EmbedResponse"
                }
              }
            },
            "description": "Embeddings"
          },
          "413": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Batch size error",
                  "error_type": "validation"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Batch size error"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Tokenization error",
                  "error_type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          },
          "424": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Inference failed",
                  "error_type": "backend"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Embedding Error"
          },
          "429": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Model is overloaded",
                  "error_type": "overloaded"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Model is overloaded"
          }
        },
        "summary": "Get Embeddings. Returns a 424 status code if the model is not an embedding model.",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/embed_all": {
      "post": {
        "description": "Returns a 424 status code if the model is not an embedding model.",
        "operationId": "embed_all",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/EmbedAllRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/EmbedAllResponse"
                }
              }
            },
            "description": "Embeddings"
          },
          "413": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Batch size error",
                  "error_type": "validation"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Batch size error"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Tokenization error",
                  "error_type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          },
          "424": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Inference failed",
                  "error_type": "backend"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Embedding Error"
          },
          "429": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Model is overloaded",
                  "error_type": "overloaded"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Model is overloaded"
          }
        },
        "summary": "Get all Embeddings without Pooling.",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/embed_sparse": {
      "post": {
        "operationId": "embed_sparse",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/EmbedSparseRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/EmbedSparseResponse"
                }
              }
            },
            "description": "Embeddings"
          },
          "413": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Batch size error",
                  "error_type": "validation"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Batch size error"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Tokenization error",
                  "error_type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          },
          "424": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Inference failed",
                  "error_type": "backend"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Embedding Error"
          },
          "429": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Model is overloaded",
                  "error_type": "overloaded"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Model is overloaded"
          }
        },
        "summary": "Get Sparse Embeddings. Returns a 424 status code if the model is not an embedding model with SPLADE pooling.",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/health": {
      "get": {
        "operationId": "health",
        "responses": {
          "200": {
            "description": "Everything is working fine"
          },
          "503": {
            "content": {
              "application/json": {
                "example": {
                  "error": "unhealthy",
                  "error_type": "unhealthy"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Text embeddings Inference is down"
          }
        },
        "summary": "Health check method",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/info": {
      "get": {
        "operationId": "get_model_info",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Info"
                }
              }
            },
            "description": "Served model info"
          }
        },
        "summary": "Text Embeddings Inference endpoint info",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/metrics": {
      "get": {
        "operationId": "metrics",
        "responses": {
          "200": {
            "content": {
              "text/plain": {
                "schema": {
                  "type": "string"
                }
              }
            },
            "description": "Prometheus Metrics"
          }
        },
        "summary": "Prometheus metrics scrape endpoint",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/predict": {
      "post": {
        "operationId": "predict",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/PredictRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PredictResponse"
                }
              }
            },
            "description": "Predictions"
          },
          "413": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Batch size error",
                  "error_type": "validation"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Batch size error"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Tokenization error",
                  "error_type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          },
          "424": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Inference failed",
                  "error_type": "backend"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Prediction Error"
          },
          "429": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Model is overloaded",
                  "error_type": "overloaded"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Model is overloaded"
          }
        },
        "summary": "Get Predictions. Returns a 424 status code if the model is not a Sequence Classification model",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/rerank": {
      "post": {
        "description": "a single class.",
        "operationId": "rerank",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/RerankRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/RerankResponse"
                }
              }
            },
            "description": "Ranks"
          },
          "413": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Batch size error",
                  "error_type": "validation"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Batch size error"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Tokenization error",
                  "error_type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          },
          "424": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Inference failed",
                  "error_type": "backend"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Rerank Error"
          },
          "429": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Model is overloaded",
                  "error_type": "overloaded"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Model is overloaded"
          }
        },
        "summary": "Get Ranks. Returns a 424 status code if the model is not a Sequence Classification model with",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/similarity": {
      "post": {
        "operationId": "similarity",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/SimilarityRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/SimilarityResponse"
                }
              }
            },
            "description": "Sentence Similarity"
          },
          "413": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Batch size error",
                  "error_type": "validation"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Batch size error"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Tokenization error",
                  "error_type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          },
          "424": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Inference failed",
                  "error_type": "backend"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Embedding Error"
          },
          "429": {
            "content": {
              "application/json": {
                "example": {
                  "error": "Model is overloaded",
                  "error_type": "overloaded"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Model is overloaded"
          }
        },
        "summary": "Get Sentence Similarity. Returns a 424 status code if the model is not an embedding model.",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/tokenize": {
      "post": {
        "operationId": "tokenize",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TokenizeRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TokenizeResponse"
                }
              }
            },
            "description": "Tokenized ids"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "message": "Tokenization error",
                  "type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          }
        },
        "summary": "Tokenize inputs",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    },
    "/v1/embeddings": {
      "post": {
        "operationId": "openai_embed",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/OpenAICompatRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/OpenAICompatResponse"
                }
              }
            },
            "description": "Embeddings"
          },
          "413": {
            "content": {
              "application/json": {
                "example": {
                  "message": "Batch size error",
                  "type": "validation"
                },
                "schema": {
                  "$ref": "#/components/schemas/OpenAICompatErrorResponse"
                }
              }
            },
            "description": "Batch size error"
          },
          "422": {
            "content": {
              "application/json": {
                "example": {
                  "message": "Tokenization error",
                  "type": "tokenizer"
                },
                "schema": {
                  "$ref": "#/components/schemas/OpenAICompatErrorResponse"
                }
              }
            },
            "description": "Tokenization error"
          },
          "424": {
            "content": {
              "application/json": {
                "example": {
                  "message": "Inference failed",
                  "type": "backend"
                },
                "schema": {
                  "$ref": "#/components/schemas/OpenAICompatErrorResponse"
                }
              }
            },
            "description": "Embedding Error"
          },
          "429": {
            "content": {
              "application/json": {
                "example": {
                  "message": "Model is overloaded",
                  "type": "overloaded"
                },
                "schema": {
                  "$ref": "#/components/schemas/OpenAICompatErrorResponse"
                }
              }
            },
            "description": "Model is overloaded"
          }
        },
        "summary": "OpenAI compatible route. Returns a 424 status code if the model is not an embedding model.",
        "tags": [
          "Text Embeddings Inference"
        ]
      }
    }
  },
  "tags": [
    {
      "description": "Hugging Face Text Embeddings Inference API",
      "name": "Text Embeddings Inference"
    }
  ]
}
