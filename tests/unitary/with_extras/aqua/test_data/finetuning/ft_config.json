{
  "configuration": {
    "learning_rate": 0.0002,
    "lora_alpha": 16,
    "lora_dropout": 0.05,
    "lora_r": 32,
    "lora_target_linear": true,
    "micro_batch_size": 1,
    "pad_to_sequence_len": true,
    "sequence_len": 2048,
    "val_set_size": 0.1
  },
  "finetuning_params": "",
  "shape": {
    "VM.GPU.A10.2": {
      "batch_size": 2,
      "replica": 1
    }
  }
}
