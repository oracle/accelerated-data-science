{
  "display_name": "config-json-files/Devstral-Small-2507-GQA",
  "recommendations": [
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU.A10.4",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 96,
          "gpu_count": 4,
          "gpu_type": "A10",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 50,
            "performance": 50
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 96.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU.B200.8",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 1440,
          "gpu_count": 8,
          "gpu_type": "B200",
          "quantization": [
            "fp4",
            "fp8",
            "fp16",
            "bf16",
            "tf32",
            "int8",
            "fp64"
          ],
          "ranking": {
            "cost": 120,
            "performance": 130
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 1440.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU.GB200.4",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 768,
          "gpu_count": 4,
          "gpu_type": "GB200",
          "quantization": [
            "fp4",
            "fp8",
            "fp6",
            "int8",
            "fp16",
            "bf16",
            "tf32",
            "fp64"
          ],
          "ranking": {
            "cost": 110,
            "performance": 120
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 768.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU.H200.8",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 1128,
          "gpu_count": 8,
          "gpu_type": "H200",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "fp8",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 100,
            "performance": 110
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 1128.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU.L40S-NC.4",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 192,
          "gpu_count": 4,
          "gpu_type": "L40S",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "fp8",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 60,
            "performance": 80
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 192.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU.L40S.4",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 192,
          "gpu_count": 4,
          "gpu_type": "L40S",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "fp8",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 60,
            "performance": 80
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 192.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU.MI300X.8",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 1536,
          "gpu_count": 8,
          "gpu_type": "MI300X",
          "quantization": [
            "fp8",
            "gguf"
          ],
          "ranking": {
            "cost": 90,
            "performance": 90
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 1536.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "BM.GPU4.8",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 320,
          "gpu_count": 8,
          "gpu_type": "A100",
          "quantization": [
            "int8",
            "fp16",
            "bf16",
            "tf32"
          ],
          "ranking": {
            "cost": 57,
            "performance": 65
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "",
            "quantization": "bfloat16",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 47.98,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 69.46
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 320.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "VM.GPU.A10.1",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 24,
          "gpu_count": 1,
          "gpu_type": "A10",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 20,
            "performance": 30
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "--max-model-len 32768 --quantization bitsandbytes --load-format bitsandbytes",
            "quantization": "4bit",
            "weight_dtype": null,
            "max_model_len": 32768,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 12.0,
            "kv_cache_size_gb": 5.37,
            "total_model_gb": 17.36
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (17.4GB used / 24.0GB allowed)."
        }
      ]
    },
    {
      "shape_details": {
        "available": false,
        "core_count": null,
        "memory_in_gbs": null,
        "name": "VM.GPU.A10.2",
        "shape_series": "GPU",
        "gpu_specs": {
          "gpu_memory_in_gbs": 48,
          "gpu_count": 2,
          "gpu_type": "A10",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 40,
            "performance": 40
          }
        }
      },
      "configurations": [
        {
          "deployment_params": {
            "params": "--quantization bitsandbytes --load-format bitsandbytes",
            "quantization": "4bit",
            "weight_dtype": null,
            "max_model_len": 131072,
            "env_var": null
          },
          "model_details": {
            "model_size_gb": 12.0,
            "kv_cache_size_gb": 21.47,
            "total_model_gb": 33.47
          },
          "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (33.5GB used / 48.0GB allowed)."
        }
      ]
    }
  ],
  "troubleshoot": ""
}