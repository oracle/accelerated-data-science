{
    "display_name": "Devstral-Small-2507-GQA",
    "recommendations": [
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.H200.8",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 1128,
                    "gpu_count": 8,
                    "gpu_type": "H200",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "fp8",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 100,
                        "performance": 110
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 47.98,
                        "kv_cache_size_gb": 21.47,
                        "total_model_gb": 69.46
                    },
                    "deployment_params": {
                        "quantization": "bfloat16",
                        "max_model_len": 131072,
                        "params": ""
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 1128.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.MI300X.8",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 1536,
                    "gpu_count": 8,
                    "gpu_type": "MI300X",
                    "quantization": [
                        "fp8",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 90,
                        "performance": 90
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 47.98,
                        "kv_cache_size_gb": 21.47,
                        "total_model_gb": 69.46
                    },
                    "deployment_params": {
                        "quantization": "bfloat16",
                        "max_model_len": 131072,
                        "params": ""
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 1536.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.L40S-NC.4",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 192,
                    "gpu_count": 4,
                    "gpu_type": "L40S",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "fp8",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 60,
                        "performance": 80
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 47.98,
                        "kv_cache_size_gb": 21.47,
                        "total_model_gb": 69.46
                    },
                    "deployment_params": {
                        "quantization": "bfloat16",
                        "max_model_len": 131072,
                        "params": ""
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 192.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.L40S.4",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 192,
                    "gpu_count": 4,
                    "gpu_type": "L40S",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "fp8",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 60,
                        "performance": 80
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 47.98,
                        "kv_cache_size_gb": 21.47,
                        "total_model_gb": 69.46
                    },
                    "deployment_params": {
                        "quantization": "bfloat16",
                        "max_model_len": 131072,
                        "params": ""
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 192.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "VM.GPU.A10.1",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 24,
                    "gpu_count": 1,
                    "gpu_type": "A10",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 20,
                        "performance": 30
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 12.0,
                        "kv_cache_size_gb": 5.37,
                        "total_model_gb": 17.36
                    },
                    "deployment_params": {
                        "quantization": "4bit",
                        "max_model_len": 32768,
                        "params": "--max-model-len 32768 --quantization bitsandbytes --load-format bitsandbytes"
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (17.4GB used / 24.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "VM.GPU.A10.2",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 48,
                    "gpu_count": 2,
                    "gpu_type": "A10",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 40,
                        "performance": 40
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 12.0,
                        "kv_cache_size_gb": 21.47,
                        "total_model_gb": 33.47
                    },
                    "deployment_params": {
                        "quantization": "4bit",
                        "max_model_len": 131072,
                        "params": " --quantization bitsandbytes --load-format bitsandbytes"
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (33.5GB used / 48.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.A10.4",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 96,
                    "gpu_count": 4,
                    "gpu_type": "A10",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 50,
                        "performance": 50
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 47.98,
                        "kv_cache_size_gb": 21.47,
                        "total_model_gb": 69.46
                    },
                    "deployment_params": {
                        "quantization": "bfloat16",
                        "max_model_len": 131072,
                        "params": ""
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (69.5GB used / 96.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU2.2",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 32,
                    "gpu_count": 2,
                    "gpu_type": "P100",
                    "quantization": [
                        "fp16"
                    ],
                    "ranking": {
                        "cost": 30,
                        "performance": 20
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 12.0,
                        "kv_cache_size_gb": 10.74,
                        "total_model_gb": 22.73
                    },
                    "deployment_params": {
                        "quantization": "4bit",
                        "max_model_len": 65536,
                        "params": "--max-model-len 65536 --quantization bitsandbytes --load-format bitsandbytes"
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (22.7GB used / 32.0GB allowed)."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "VM.GPU2.1",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 16,
                    "gpu_count": 1,
                    "gpu_type": "P100",
                    "quantization": [
                        "fp16"
                    ],
                    "ranking": {
                        "cost": 10,
                        "performance": 10
                    }
                }
            },
            "configurations": [
                {
                    "model_details": {
                        "model_size_gb": 12.0,
                        "kv_cache_size_gb": 1.34,
                        "total_model_gb": 13.34
                    },
                    "deployment_params": {
                        "quantization": "4bit",
                        "max_model_len": 8192,
                        "params": "--max-model-len 8192 --quantization bitsandbytes --load-format bitsandbytes"
                    },
                    "recommendation": "No override PARAMS needed. \n\nModel fits well within the allowed compute shape (13.3GB used / 16.0GB allowed)."
                }
            ]
        }
    ],
    "troubleshoot": ""
}