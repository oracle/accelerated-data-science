{
  "display_name": "service-config/example-2",
  "recommendations": [
    {
      "configurations": [
        {
          "deployment_params": {
            "env_var": {
              "VLLM_ATTENTION_BACKEND": "TRITON_ATTN_VLLM_V1"
            },
            "max_model_len": 130000,
            "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 32 --max-model-len 130000 --dtype bfloat16",
            "quantization": null,
            "weight_dtype": "bfloat16"
          },
          "model_details": null,
          "recommendation": "ENV: {\"VLLM_ATTENTION_BACKEND\": \"TRITON_ATTN_VLLM_V1\"}\n\nModel fits well within the allowed compute shape."
        }
      ],
      "shape_details": {
        "available": false,
        "core_count": null,
        "gpu_specs": {
          "cpu_count": 64,
          "cpu_memory_in_gbs": 1024,
          "gpu_count": 4,
          "gpu_memory_in_gbs": 96,
          "gpu_type": "A10",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 50,
            "performance": 50
          }
        },
        "memory_in_gbs": null,
        "name": "BM.GPU.A10.4",
        "shape_series": "GPU"
      }
    },
    {
      "configurations": [
        {
          "deployment_params": {
            "env_var": null,
            "max_model_len": 130000,
            "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 32 --max-model-len 130000 --dtype bfloat16",
            "quantization": null,
            "weight_dtype": "bfloat16"
          },
          "model_details": null,
          "recommendation": "Model fits well within the allowed compute shape."
        }
      ],
      "shape_details": {
        "available": false,
        "core_count": null,
        "gpu_specs": {
          "cpu_count": 64,
          "cpu_memory_in_gbs": 2048,
          "gpu_count": 8,
          "gpu_memory_in_gbs": 320,
          "gpu_type": "A100",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 70,
            "performance": 60
          }
        },
        "memory_in_gbs": null,
        "name": "BM.GPU.B4.8",
        "shape_series": "GPU"
      }
    },
    {
      "configurations": [
        {
          "deployment_params": {
            "env_var": null,
            "max_model_len": 130000,
            "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 64 --max-model-len 130000 --quantization mxfp4",
            "quantization": "mxfp4",
            "weight_dtype": null
          },
          "model_details": null,
          "recommendation": "Model fits well within the allowed compute shape."
        }
      ],
      "shape_details": {
        "available": false,
        "core_count": null,
        "gpu_specs": {
          "cpu_count": 112,
          "cpu_memory_in_gbs": 2048,
          "gpu_count": 8,
          "gpu_memory_in_gbs": 640,
          "gpu_type": "H100",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "fp8",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 100,
            "performance": 100
          }
        },
        "memory_in_gbs": null,
        "name": "BM.GPU.H100.8",
        "shape_series": "GPU"
      }
    },
    {
      "configurations": [
        {
          "deployment_params": {
            "env_var": null,
            "max_model_len": 130000,
            "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 64 --max-model-len 130000 --quantization mxfp4",
            "quantization": "mxfp4",
            "weight_dtype": null
          },
          "model_details": null,
          "recommendation": "Model fits well within the allowed compute shape."
        }
      ],
      "shape_details": {
        "available": false,
        "core_count": null,
        "gpu_specs": {
          "cpu_count": 112,
          "cpu_memory_in_gbs": 3072,
          "gpu_count": 8,
          "gpu_memory_in_gbs": 1128,
          "gpu_type": "H200",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "fp8",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 100,
            "performance": 110
          }
        },
        "memory_in_gbs": null,
        "name": "BM.GPU.H200.8",
        "shape_series": "GPU"
      }
    },
    {
      "configurations": [
        {
          "deployment_params": {
            "env_var": {
              "VLLM_ATTENTION_BACKEND": "TRITON_ATTN_VLLM_V1"
            },
            "max_model_len": 130000,
            "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 32 --max-model-len 130000 --dtype bfloat16",
            "quantization": null,
            "weight_dtype": "bfloat16"
          },
          "model_details": null,
          "recommendation": "ENV: {\"VLLM_ATTENTION_BACKEND\": \"TRITON_ATTN_VLLM_V1\"}\n\nModel fits well within the allowed compute shape."
        }
      ],
      "shape_details": {
        "available": false,
        "core_count": null,
        "gpu_specs": {
          "cpu_count": 64,
          "cpu_memory_in_gbs": 2048,
          "gpu_count": 8,
          "gpu_memory_in_gbs": 320,
          "gpu_type": "A100",
          "quantization": [
            "int8",
            "fp16",
            "bf16",
            "tf32"
          ],
          "ranking": {
            "cost": 57,
            "performance": 65
          }
        },
        "memory_in_gbs": null,
        "name": "BM.GPU4.8",
        "shape_series": "GPU"
      }
    },
    {
      "configurations": [
        {
          "deployment_params": {
            "env_var": {
              "VLLM_ATTENTION_BACKEND": "TRITON_ATTN_VLLM_V1"
            },
            "max_model_len": 8192,
            "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 5 --max-model-len 8192 --dtype bfloat16",
            "quantization": null,
            "weight_dtype": "bfloat16"
          },
          "model_details": null,
          "recommendation": "ENV: {\"VLLM_ATTENTION_BACKEND\": \"TRITON_ATTN_VLLM_V1\"}\n\nModel fits well within the allowed compute shape."
        }
      ],
      "shape_details": {
        "available": false,
        "core_count": null,
        "gpu_specs": {
          "cpu_count": 30,
          "cpu_memory_in_gbs": 480,
          "gpu_count": 2,
          "gpu_memory_in_gbs": 48,
          "gpu_type": "A10",
          "quantization": [
            "awq",
            "gptq",
            "marlin",
            "int8",
            "bitblas",
            "aqlm",
            "bitsandbytes",
            "deepspeedfp",
            "gguf"
          ],
          "ranking": {
            "cost": 40,
            "performance": 40
          }
        },
        "memory_in_gbs": null,
        "name": "VM.GPU.A10.2",
        "shape_series": "GPU"
      }
    }
  ],
  "troubleshoot": null
}
