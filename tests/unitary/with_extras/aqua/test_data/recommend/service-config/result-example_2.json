{
    "display_name": "service-config/example_2",
    "recommendations": [
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.H200.8",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 1128,
                    "gpu_count": 8,
                    "gpu_type": "H200",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "fp8",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 100,
                        "performance": 110
                    }
                }
            },
            "configurations": [
                {
                    "deployment_params": {
                        "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 64 --max-model-len 130000 --quantization mxfp4",
                        "quantization": "mxfp4",
                        "weight_dtype": null,
                        "max_model_len": 130000,
                        "env_var": null
                    },
                    "model_details": null,
                    "recommendation": "Model fits well within the allowed compute shape."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.H100.8",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 640,
                    "gpu_count": 8,
                    "gpu_type": "H100",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "fp8",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 100,
                        "performance": 100
                    }
                }
            },
            "configurations": [
                {
                    "deployment_params": {
                        "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 64 --max-model-len 130000 --quantization mxfp4",
                        "quantization": "mxfp4",
                        "weight_dtype": null,
                        "max_model_len": 130000,
                        "env_var": null
                    },
                    "model_details": null,
                    "recommendation": "Model fits well within the allowed compute shape."
                }
            ]
        },
        {
            "shape_details": {
                "available": false,
                "core_count": null,
                "memory_in_gbs": null,
                "name": "BM.GPU.B4.8",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 320,
                    "gpu_count": 8,
                    "gpu_type": "A100",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 70,
                        "performance": 60
                    }
                }
            },
            "configurations": [
                {
                    "deployment_params": {
                        "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 32 --max-model-len 130000 --dtype bfloat16",
                        "quantization": null,
                        "weight_dtype": "bfloat16",
                        "max_model_len": 130000,
                        "env_var": null
                    },
                    "model_details": null,
                    "recommendation": "Model fits well within the allowed compute shape."
                }
            ]
        },
        {
            "shape_details": {
                "available": true,
                "core_count": 64,
                "memory_in_gbs": 2048,
                "name": "BM.GPU4.8",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 320,
                    "gpu_count": 8,
                    "gpu_type": "A100",
                    "quantization": [
                        "int8",
                        "fp16",
                        "bf16",
                        "tf32"
                    ],
                    "ranking": {
                        "cost": 57,
                        "performance": 65
                    }
                }
            },
            "configurations": [
                {
                    "deployment_params": {
                        "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 32 --max-model-len 130000 --dtype bfloat16",
                        "quantization": null,
                        "weight_dtype": "bfloat16",
                        "max_model_len": 130000,
                        "env_var": {
                            "VLLM_ATTENTION_BACKEND": "TRITON_ATTN_VLLM_V1"
                        }
                    },
                    "model_details": null,
                    "recommendation": "ENV: {\"VLLM_ATTENTION_BACKEND\": \"TRITON_ATTN_VLLM_V1\"}\n\nModel fits well within the allowed compute shape."
                }
            ]
        },
        {
            "shape_details": {
                "available": true,
                "core_count": 64,
                "memory_in_gbs": 1024,
                "name": "BM.GPU.A10.4",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 96,
                    "gpu_count": 4,
                    "gpu_type": "A10",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 50,
                        "performance": 50
                    }
                }
            },
            "configurations": [
                {
                    "deployment_params": {
                        "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 32 --max-model-len 130000 --dtype bfloat16",
                        "quantization": null,
                        "weight_dtype": "bfloat16",
                        "max_model_len": 130000,
                        "env_var": {
                            "VLLM_ATTENTION_BACKEND": "TRITON_ATTN_VLLM_V1"
                        }
                    },
                    "model_details": null,
                    "recommendation": "ENV: {\"VLLM_ATTENTION_BACKEND\": \"TRITON_ATTN_VLLM_V1\"}\n\nModel fits well within the allowed compute shape."
                }
            ]
        },
        {
            "shape_details": {
                "available": true,
                "core_count": 30,
                "memory_in_gbs": 480,
                "name": "VM.GPU.A10.2",
                "shape_series": "GPU",
                "gpu_specs": {
                    "gpu_memory_in_gbs": 48,
                    "gpu_count": 2,
                    "gpu_type": "A10",
                    "quantization": [
                        "awq",
                        "gptq",
                        "marlin",
                        "int8",
                        "bitblas",
                        "aqlm",
                        "bitsandbytes",
                        "deepspeedfp",
                        "gguf"
                    ],
                    "ranking": {
                        "cost": 40,
                        "performance": 40
                    }
                }
            },
            "configurations": [
                {
                    "deployment_params": {
                        "params": "--trust-remote-code --gpu-memory-utilization 0.90 --max-num-seqs 5 --max-model-len 8192 --dtype bfloat16",
                        "quantization": null,
                        "weight_dtype": "bfloat16",
                        "max_model_len": 8192,
                        "env_var": {
                            "VLLM_ATTENTION_BACKEND": "TRITON_ATTN_VLLM_V1"
                        }
                    },
                    "model_details": null,
                    "recommendation": "ENV: {\"VLLM_ATTENTION_BACKEND\": \"TRITON_ATTN_VLLM_V1\"}\n\nModel fits well within the allowed compute shape."
                }
            ]
        }
    ],
    "troubleshoot": null
}