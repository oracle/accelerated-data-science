{
  "containerSpec": {
    "odsc-tgi-serving": {
      "cliParam": "--sharded true --trust-remote-code",
      "envVars": [
        {
          "MODEL_DEPLOY_PREDICT_ENDPOINT": "/v1/completions"
        },
        {
          "MODEL_DEPLOY_ENABLE_STREAMING": "true"
        },
        {
          "PORT": "8080"
        },
        {
          "HEALTH_CHECK_PORT": "8080"
        }
      ],
      "healthCheckPort": "8080",
      "serverPort": "8080"
    },
    "odsc-vllm-serving": {
      "cliParam": "--served-model-name $(python -c 'import os; print(os.environ.get(\"ODSC_SERVED_MODEL_NAME\",\"odsc-llm\"))') --seed 42 ",
      "envVars": [
        {
          "MODEL_DEPLOY_PREDICT_ENDPOINT": "/v1/completions"
        },
        {
          "MODEL_DEPLOY_ENABLE_STREAMING": "true"
        },
        {
          "PORT": "8080"
        },
        {
          "HEALTH_CHECK_PORT": "8080"
        }
      ],
      "healthCheckPort": "8080",
      "serverPort": "8080"
    }
  },
  "odsc-llm-evaluate": [
    {
      "name": "dsmc://odsc-llm-evaluate",
      "version": "0.1.2.0"
    }
  ],
  "odsc-llm-fine-tuning": [
    {
      "name": "dsmc://odsc-llm-fine-tuning",
      "version": "1.1.33.34"
    }
  ],
  "odsc-tgi-serving": [
    {
      "displayName": "TGI:1.4.5",
      "name": "dsmc://odsc-tgi-serving",
      "type": "inference",
      "version": "1.4.5"
    },
    {
      "displayName": "TGI:2.0.2",
      "name": "dsmc://odsc-tgi-serving",
      "type": "inference",
      "version": "2.0.2"
    }
  ],
  "odsc-vllm-serving": [
    {
      "displayName": "VLLM:0.3.0",
      "name": "dsmc://odsc-vllm-serving",
      "type": "inference",
      "version": "0.3.0.7"
    }
  ]
}
